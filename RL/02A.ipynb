{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6edb1dbe-20ad-49d3-aabf-27a0438da7e0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b1d6d12-e770-47ce-a9eb-fb93b7a2b755",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "import tensorflow as tf\n",
    "import tqdm.notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from gymnasium.utils.save_video import save_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "011e03a4-a0ea-4ce2-9f00-e09b9b4c2e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "              tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e580a6f-a987-40ec-9864-2e296bdd9ba6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120abf50-431d-4c8c-bc71-e760aa7c08b4",
   "metadata": {},
   "source": [
    "Create the environment. You can use any ATARI environment from [here](https://gymnasium.farama.org/environments/atari/), but prefer to use environments with discrete action space with fewer actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95030528",
   "metadata": {},
   "outputs": [],
   "source": [
    "atari_game_name = 'ALE/Asterix-v5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c9241b5-510e-4a18-bcde-8bf3c5ac2b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "enviroment = gym.make(atari_game_name, render_mode='rgb_array')\n",
    "eval_enviroment = gym.make(atari_game_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d50e1d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programs\\Anaconda\\envs\\venv\\lib\\site-packages\\gymnasium\\utils\\passive_env_checker.py:335: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x269c1881420>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "enviroment.reset()\n",
    "plt.imshow(enviroment.render())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6828a718-db96-42f6-890f-265163fdedb9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Replay Buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037a88e3-0524-4d4f-9bd5-eb035d80fece",
   "metadata": {},
   "source": [
    "Create a replay buffer to hold game history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a761715-1ef6-4ffd-b710-1758f292888c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "\n",
    "    def __init__(self, max_size: int, observation_space: gym.spaces.Space, action_space: gym.spaces.Space, seed: int | None = None):\n",
    "        \"\"\"Stores the replay history with a maximum of `max_size` entries, removing old entries as needed.\n",
    "\n",
    "        Parameters:\n",
    "            max_size: maximal number of entries to keep\n",
    "            observation_space: specification of the observation space\n",
    "            action_space: specification of the action space\n",
    "            seed: seed to initialize the internal random number generator for reproducibility\"\"\"\n",
    "        self.max_size = max_size\n",
    "        self.done = np.zeros(max_size)\n",
    "        self.step = 0\n",
    "        self.rng = np.random.default_rng(seed=seed)\n",
    "        self.len = 0\n",
    "\n",
    "        self.current_state = np.zeros((max_size, *observation_space.shape))\n",
    "        self.action = np.zeros((max_size, *action_space.shape), dtype=int)\n",
    "        self.reward = np.zeros(max_size)\n",
    "        self.next_state = np.zeros((max_size, *observation_space.shape))\n",
    "        \n",
    "    def add(self, current_observation: np.ndarray, action: int, reward: float, next_observation: np.ndarray, done: bool) -> None:\n",
    "        \"\"\"Add a new entry to the buffer.\n",
    "\n",
    "        Parameters:\n",
    "            current_observation: environment state observed at the current step\n",
    "            action: action taken by the model\n",
    "            reward: reward received after taking the action\n",
    "            next_observation: environment state obversed after taking the action\n",
    "            done: whether the episode has ended or not\"\"\"\n",
    "        self.current_state[self.step] = current_observation\n",
    "        self.action[self.step] = action\n",
    "        self.reward[self.step] = reward\n",
    "        self.next_state[self.step] = next_observation\n",
    "        self.done[self.step] = done\n",
    "        self.step = (self.step + 1) % self.max_size\n",
    "        self.len = min(self.len + 1, self.max_size)\n",
    "        \n",
    "    def sample(self, n_samples: int, replace: bool = True) -> tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "        \"\"\"Randomly samples `n_samples` from the buffer.\n",
    "\n",
    "        Parameters:\n",
    "            n_samples: number of samples to select\n",
    "            replace: sample with or without replacement\n",
    "\n",
    "        Returns:\n",
    "            current observations, actions, rewards, next observations, done\"\"\"\n",
    "        indicies = self.rng.choice(self.len, size=n_samples, replace=replace)\n",
    "        return (\n",
    "            self.current_state[indicies], \n",
    "            self.action[indicies], \n",
    "            self.reward[indicies], \n",
    "            self.next_state[indicies], \n",
    "            self.done[indicies]\n",
    "        )\n",
    "\n",
    "    def clear(self) -> None:\n",
    "        \"\"\"Clears the buffer\"\"\"\n",
    "        self.step = self.len = 0\n",
    "\n",
    "    def __getitem__(self, index: int) -> tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "        \"\"\"Gets a sample at `index`\n",
    "\n",
    "        Parameters:\n",
    "            index: index of the sample to get\n",
    "\n",
    "        Returns:\n",
    "            current observation, action, reward, next observation, done\"\"\"\n",
    "        return (\n",
    "            self.current_state[index], \n",
    "            self.action[index], \n",
    "            self.reward[index], \n",
    "            self.next_state[index], \n",
    "            self.done[index]\n",
    "        )\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Returns the number of entries in the buffer\"\"\"\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669485c5-5787-4ffa-82f2-58f6f0acc151",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc62c869-195b-4323-bdb4-dd53879455c9",
   "metadata": {},
   "source": [
    "Implement your model. Most if not all ATARI environments have an image observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bd7fbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(prefix: str | None = None, suffix: str | None = None, separator: str = '/') -> str | None:\n",
    "    return prefix and prefix + separator + suffix or suffix or None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a572a086-e9ce-4194-8809-54a8e05477d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(\n",
    "    input_features: tuple | int, \n",
    "    features: int,\n",
    "    out_features: tuple | int,\n",
    "    blocks: int, \n",
    "    dropout: float = 0.,\n",
    "    multiply_freq: int = 1,\n",
    "    name: str | None = None\n",
    ") -> tf.keras.Model:\n",
    "    inputs = x = tf.keras.layers.Input(input_features, name=get_name(name, 'input'))\n",
    "\n",
    "    for i in range(blocks):\n",
    "        x = tf.keras.layers.Conv2D(features, 3, padding='same', name=get_name(name, f'Conv2D_f_{i}'))(x)\n",
    "        x = tf.keras.layers.PReLU(name=get_name(name, f'PReLU_f_{i}'))(x)\n",
    "\n",
    "        x = tf.keras.layers.Conv2D(features, 3, padding='same', name=get_name(name, f'Conv2D_s_{i}'))(x)\n",
    "        x = tf.keras.layers.PReLU(name=get_name(name, f'PReLU_s_{i}'))(x)\n",
    "        \n",
    "        x = tf.keras.layers.MaxPooling2D((2, 2), name=get_name(name, f'PMaxPooling2D_{i}'))(x)\n",
    "\n",
    "        if multiply_freq > 0 and (i + 1) % multiply_freq == 0:\n",
    "            features *= 2\n",
    "\n",
    "        if dropout > 0:\n",
    "            x = tf.keras.layers.Dropout(dropout, name=get_name(name, f'Dropout_{i}'))(x)\n",
    "\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D(name=get_name(name, f'GlobalAveragePooling2D'))(x)\n",
    "    x = tf.keras.layers.Dense(out_features, name=get_name(name, 'Prediction'))(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs=inputs, outputs=x, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8f6a53-ffa2-44ee-985b-a8bd921592fb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e44c932-378b-4bff-b11d-20b4b879de9a",
   "metadata": {},
   "source": [
    "Implement the sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2de070f1-c6b7-4a4a-81ae-e471f159e6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampler:\n",
    "    \n",
    "    def __init__(self, epsilon: float, seed: int | None = None):\n",
    "        \"\"\"Selects a random action with probability `epsilon` otherwise selects the most probably action given by the model.\n",
    "\n",
    "        Parameters:\n",
    "            epsilon: the probability to select a random action\n",
    "            seed: seed to initialize the internal random number generator for reproducibility\"\"\"\n",
    "        self.rng = np.random.default_rng(seed=seed)\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    def __call__(self, probabilities: np.ndarray) -> int:\n",
    "        \"\"\"Select an action given the `probabilities\n",
    "\n",
    "        Parameters:\n",
    "            probabilities: probabilities for each action\n",
    "\n",
    "        Returns:\n",
    "            index of the selected action\"\"\"\n",
    "\n",
    "        if self.rng.random() < self.epsilon:\n",
    "            return self.rng.integers(probabilities.shape[-1])\n",
    "        return np.argmax(probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2cc1a3-3e45-4aac-8936-d5d45cc256f1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Play the game"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02aa11b5-0ca1-4bfb-91a0-33a4f8922ae9",
   "metadata": {},
   "source": [
    "Implement interacting with the environment and storing entries to the replay buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b333e6b3-853a-4cb7-aea3-8c501d0247d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_game(model: tf.keras.Model, buffer: ReplayBuffer | None, env: gym.Env, max_steps: int, sampler: Sampler, observation: np.ndarray | None = None) -> Tuple[np.ndarray, list]:\n",
    "    \"\"\"Play game and record\n",
    "\n",
    "    Parameters:\n",
    "        model: the model to get actions with\n",
    "        buffer: replay buffer to store the entries to\n",
    "        env: environment to play\n",
    "        max_steps: maximal number of steps to perform\n",
    "        sampler: sampler to use to sample actions\n",
    "        observation: the observation to resume from\n",
    "\n",
    "    Returns:\n",
    "        the last observation\"\"\"\n",
    "    if observation is None:\n",
    "        observation, _ = env.reset()\n",
    "\n",
    "    renders = []\n",
    "\n",
    "    buffer = buffer if buffer is not None else ReplayBuffer(1)\n",
    "\n",
    "    for i in range(max_steps):\n",
    "        a = sampler(model(observation[None], training=False).numpy()[0])\n",
    "        \n",
    "        new_observation, score, done, terminated, _ = env.step(a)\n",
    "        \n",
    "        buffer.add(observation, a, score, new_observation, done)\n",
    "\n",
    "        if done or terminated:\n",
    "            renders.append(env.render())\n",
    "            observation, _ = env.reset()\n",
    "            continue\n",
    "            \n",
    "        observation = new_observation\n",
    "\n",
    "    return observation, renders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971ad3a7-0487-49d3-9ca4-6b6bbc3fa450",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcbeef8-70fb-44ae-92e9-0baea77e8f0e",
   "metadata": {},
   "source": [
    "Implement double q learning loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9775cbc-77a8-4b02-ab0a-3fbb22b3e958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qq_loss(\n",
    "    current_observation: tf.Tensor, \n",
    "    action: tf.Tensor, \n",
    "    reward: tf.Tensor, \n",
    "    next_observation: tf.Tensor, \n",
    "    done: tf.Tensor,\n",
    "    model: tf.keras.Model,\n",
    "    target_model: tf.keras.Model,\n",
    "    gamma: float\n",
    ") -> tf.Tensor:\n",
    "    \"\"\"Computes double q learning loss.\n",
    "\n",
    "    Parameters:\n",
    "        current_observation: observations at the current time step\n",
    "        action: actions taken at the current time step\n",
    "        reward: rewards at the current time step\n",
    "        next_observation: observations at the next time step\n",
    "        done: whether the episode has ended or not\n",
    "        model: trainig model\n",
    "        target_model: target model\n",
    "        gamma: discount\n",
    "\n",
    "    Returns:\n",
    "        Computed loss\"\"\"\n",
    "    q_current = model(current_observation)\n",
    "    q_next = target_model(next_observation)\n",
    "\n",
    "    a_next = tf.argmax(model(next_observation), axis=-1)\n",
    "    \n",
    "    q_ref = reward + gamma * tf.reshape(tf.gather(q_next, tf.expand_dims(a_next, axis=-1), batch_dims=1), (-1, )) * (1. - done)\n",
    "    \n",
    "    q = tf.reshape(tf.gather(q_current, tf.expand_dims(action, axis=-1), batch_dims=1), (-1, ))\n",
    "\n",
    "    return tf.math.reduce_mean(tf.square(q_ref - q))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78458a1f-054a-463a-934f-ac3f669c0e27",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb0aaa7-6ae5-45dc-9c52-04c474ec3ecc",
   "metadata": {},
   "source": [
    "Create models, replay buffers, sampler, optimizer, epsilon decay etc. Implement training loop, show training progress and perform model evaluation once in a while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "139138b8-f63c-4a2f-8793-4f96d25a353a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(enviroment.observation_space.shape, 10, 9, 4, name='test_1', dropout=0.3, multiply_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ed6857d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"test_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " test_1/input (InputLayer)   [(None, 210, 160, 3)]     0         \n",
      "                                                                 \n",
      " test_1/Conv2D_f_0 (Conv2D)  (None, 210, 160, 10)      280       \n",
      "                                                                 \n",
      " test_1/PReLU_f_0 (PReLU)    (None, 210, 160, 10)      336000    \n",
      "                                                                 \n",
      " test_1/Conv2D_s_0 (Conv2D)  (None, 210, 160, 10)      910       \n",
      "                                                                 \n",
      " test_1/PReLU_s_0 (PReLU)    (None, 210, 160, 10)      336000    \n",
      "                                                                 \n",
      " test_1/PMaxPooling2D_0 (Max  (None, 105, 80, 10)      0         \n",
      " Pooling2D)                                                      \n",
      "                                                                 \n",
      " test_1/Dropout_0 (Dropout)  (None, 105, 80, 10)       0         \n",
      "                                                                 \n",
      " test_1/Conv2D_f_1 (Conv2D)  (None, 105, 80, 10)       910       \n",
      "                                                                 \n",
      " test_1/PReLU_f_1 (PReLU)    (None, 105, 80, 10)       84000     \n",
      "                                                                 \n",
      " test_1/Conv2D_s_1 (Conv2D)  (None, 105, 80, 10)       910       \n",
      "                                                                 \n",
      " test_1/PReLU_s_1 (PReLU)    (None, 105, 80, 10)       84000     \n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " test_1/input (InputLayer)   [(None, 210, 160, 3)]     0         \n",
      "                                                                 \n",
      " test_1/Conv2D_f_0 (Conv2D)  (None, 210, 160, 10)      280       \n",
      "                                                                 \n",
      " test_1/PReLU_f_0 (PReLU)    (None, 210, 160, 10)      336000    \n",
      "                                                                 \n",
      " test_1/Conv2D_s_0 (Conv2D)  (None, 210, 160, 10)      910       \n",
      "                                                                 \n",
      " test_1/PReLU_s_0 (PReLU)    (None, 210, 160, 10)      336000    \n",
      "                                                                 \n",
      " test_1/PMaxPooling2D_0 (Max  (None, 105, 80, 10)      0         \n",
      " Pooling2D)                                                      \n",
      "                                                                 \n",
      " test_1/Dropout_0 (Dropout)  (None, 105, 80, 10)       0         \n",
      "                                                                 \n",
      " test_1/Conv2D_f_1 (Conv2D)  (None, 105, 80, 10)       910       \n",
      "                                                                 \n",
      " test_1/PReLU_f_1 (PReLU)    (None, 105, 80, 10)       84000     \n",
      "                                                                 \n",
      " test_1/Conv2D_s_1 (Conv2D)  (None, 105, 80, 10)       910       \n",
      "                                                                 \n",
      " test_1/PReLU_s_1 (PReLU)    (None, 105, 80, 10)       84000     \n",
      "                                                                 \n",
      " test_1/PMaxPooling2D_1 (Max  (None, 52, 40, 10)       0         \n",
      " Pooling2D)                                                      \n",
      "                                                                 \n",
      " test_1/Dropout_1 (Dropout)  (None, 52, 40, 10)        0         \n",
      "                                                                 \n",
      " test_1/Conv2D_f_2 (Conv2D)  (None, 52, 40, 20)        1820      \n",
      "                                                                 \n",
      " test_1/PReLU_f_2 (PReLU)    (None, 52, 40, 20)        41600     \n",
      "                                                                 \n",
      " test_1/Conv2D_s_2 (Conv2D)  (None, 52, 40, 20)        3620      \n",
      "                                                                 \n",
      " test_1/PReLU_s_2 (PReLU)    (None, 52, 40, 20)        41600     \n",
      "                                                                 \n",
      " test_1/PMaxPooling2D_2 (Max  (None, 26, 20, 20)       0         \n",
      " Pooling2D)                                                      \n",
      "                                                                 \n",
      " test_1/Dropout_2 (Dropout)  (None, 26, 20, 20)        0         \n",
      "                                                                 \n",
      " test_1/Conv2D_f_3 (Conv2D)  (None, 26, 20, 20)        3620      \n",
      "                                                                 \n",
      " test_1/PReLU_f_3 (PReLU)    (None, 26, 20, 20)        10400     \n",
      "                                                                 \n",
      " test_1/Conv2D_s_3 (Conv2D)  (None, 26, 20, 20)        3620      \n",
      "                                                                 \n",
      " test_1/PReLU_s_3 (PReLU)    (None, 26, 20, 20)        10400     \n",
      "                                                                 \n",
      " test_1/PMaxPooling2D_3 (Max  (None, 13, 10, 20)       0         \n",
      " Pooling2D)                                                      \n",
      "                                                                 \n",
      " test_1/Dropout_3 (Dropout)  (None, 13, 10, 20)        0         \n",
      "                                                                 \n",
      " test_1/GlobalAveragePooling  (None, 20)               0         \n",
      " 2D (GlobalAveragePooling2D)                                     \n",
      "                                                                 \n",
      " test_1/Prediction (Dense)   (None, 9)                 189       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 959,879\n",
      "Trainable params: 959,879\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7062a6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_model = get_model(enviroment.observation_space.shape, 10, 9, 4, name='test_target', dropout=0.3, multiply_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b61bd83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_model.trainable = False\n",
    "target_model.set_weights(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2cb5084d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_buffer = ReplayBuffer(15000, observation_space=enviroment.observation_space, action_space=enviroment.action_space)\n",
    "train_sampler = Sampler(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0bc1276a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_buffer = ReplayBuffer(500, observation_space=eval_enviroment.observation_space, action_space=eval_enviroment.action_space)\n",
    "eval_sampler = Sampler(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c046ed09",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(1e-4, clipnorm=5, decay=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c0fbdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 12000\n",
    "batch_size = 64\n",
    "decay_epochs = epochs // 2\n",
    "end_epsilon = 0.1\n",
    "update_frequency = 512\n",
    "eval_frequency = 512\n",
    "steps_per_epoch = 32\n",
    "eval_steps = 1500\n",
    "#initial_samples = 1000\n",
    "n_evals = 8\n",
    "eval_threshold = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "875a51ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon_decay = tf.keras.optimizers.schedules.PolynomialDecay(1., decay_epochs, end_learning_rate=end_epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f0725f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c92b34d1d9f14115b6f23d063fe36637",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses = []\n",
    "total_loss = 0\n",
    "eval_score = 0\n",
    "best_score = 0\n",
    "\n",
    "s, _ = enviroment.reset()\n",
    "pbar = tqdm.trange(epochs)\n",
    "for i in pbar:\n",
    "    train_sampler.epsilon = epsilon_decay(i).numpy()\n",
    "    \n",
    "    s, _ = play_game(model, train_buffer, enviroment, steps_per_epoch, train_sampler, observation=s)\n",
    "    \n",
    "    vals = train_buffer.sample(batch_size)\n",
    "    with tf.GradientTape(watch_accessed_variables=False) as g:\n",
    "        g.watch(model.trainable_weights)\n",
    "        loss = qq_loss(*vals, model, target_model, 0.99)\n",
    "        \n",
    "    gradient = g.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(gradient, model.trainable_weights))\n",
    "    \n",
    "    losses.append(loss.numpy())\n",
    "    total_loss += losses[-1]\n",
    "\n",
    "    if (i + 1) % update_frequency == 0:\n",
    "        target_model.set_weights(model.get_weights())\n",
    "\n",
    "    if (i + 1) % eval_frequency == 0:\n",
    "        if best_score < eval_score:\n",
    "            best_score = eval_score\n",
    "\n",
    "            model_directory = f'./my_models/dir_model_{best_score}/'\n",
    "            \n",
    "            if not os.path.exists(model_directory):\n",
    "                os.makedirs(model_directory)\n",
    "            \n",
    "            model.save_weights(model_directory + f'model_{best_score}')\n",
    "        \n",
    "        eval_score = 0\n",
    "\n",
    "        for _ in range(n_evals):\n",
    "            eval_buffer.clear()\n",
    "            play_game(model, eval_buffer, eval_enviroment, eval_steps, eval_sampler)\n",
    "            eval_score += eval_buffer.reward[:len(eval_buffer)].sum()\n",
    "\n",
    "        eval_score /= n_evals\n",
    "        if eval_score >= eval_threshold:\n",
    "            break\n",
    "\n",
    "    pbar.set_description(f'L: {losses[-1]:.5f}; AL: {total_loss / (i + 1):.5f}; E: {eval_score:.5f}; BE: {best_score:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7427abbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "enviroment.close()\n",
    "eval_enviroment.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd5b44e-55cd-43bb-89dd-87c28cc10a9c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965e5731-8d24-4482-82ed-7226fb18fa5c",
   "metadata": {},
   "source": [
    "Test the model on the environment and get a cool video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "72ec281c-d005-499a-b416-4d0e43437a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_gameplay(model: tf.keras.Model, render_mode: str = 'human', n_frames: int = 1000, buffer_capacity: int = 1000):\n",
    "    env = gym.make(atari_game_name, render_mode=render_mode)\n",
    "    buffer = ReplayBuffer(buffer_capacity, env.observation_space, env.action_space)\n",
    "    play_game(model, buffer, env, n_frames, Sampler(0))\n",
    "    \n",
    "    if render_mode != 'human':\n",
    "        save_video(env.render(), './videos', video_length=n_frames, fps=24) #if you wanna use this line change 'render_mode' -> 'rgb_array_list'\n",
    "    \n",
    "    return buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "71cc8eeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x269d4947c40>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('./my_models/dir_model_825.0/model_825.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "93564ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programs\\Anaconda\\envs\\venv\\lib\\site-packages\\gymnasium\\utils\\passive_env_checker.py:335: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "buffer = save_gameplay(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7356af55",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'buffer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mbuffer\u001b[49m\u001b[38;5;241m.\u001b[39mreward\u001b[38;5;241m.\u001b[39msum()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'buffer' is not defined"
     ]
    }
   ],
   "source": [
    "buffer.reward.sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
