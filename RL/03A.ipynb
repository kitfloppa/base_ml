{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6edb1dbe-20ad-49d3-aabf-27a0438da7e0",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b1d6d12-e770-47ce-a9eb-fb93b7a2b755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "import tensorflow as tf\n",
    "import tqdm.notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from gymnasium.utils.save_video import save_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "011e03a4-a0ea-4ce2-9f00-e09b9b4c2e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "              tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e580a6f-a987-40ec-9864-2e296bdd9ba6",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120abf50-431d-4c8c-bc71-e760aa7c08b4",
   "metadata": {},
   "source": [
    "Create the [environment](https://gymnasium.farama.org/environments/box2d/bipedal_walker/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6e928e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = 'BipedalWalker-v3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c9241b5-510e-4a18-bcde-8bf3c5ac2b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "enviroment = gym.make(env_name, render_mode='rgb_array', hardcore=False)\n",
    "eval_enviroment = gym.make(env_name, hardcore=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e83c25bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2b0fe1490c0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "enviroment.reset()\n",
    "plt.imshow(enviroment.render())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6828a718-db96-42f6-890f-265163fdedb9",
   "metadata": {},
   "source": [
    "# Replay Buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037a88e3-0524-4d4f-9bd5-eb035d80fece",
   "metadata": {},
   "source": [
    "Create a replay buffer to hold game history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a761715-1ef6-4ffd-b710-1758f292888c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "\n",
    "    def __init__(self, max_size: int, observation_space: gym.spaces.Space, action_space: gym.spaces.Space, seed: int | None = None):\n",
    "        \"\"\"Stores the replay history with a maximum of `max_size` entries, removing old entries as needed.\n",
    "\n",
    "        Parameters:\n",
    "            max_size: maximal number of entries to keep\n",
    "            observation_space: specification of the observation space\n",
    "            action_space: specification of the action space\n",
    "            seed: seed to initialize the internal random number generator for reproducibility\"\"\"\n",
    "\n",
    "        self.max_size = max_size\n",
    "        \n",
    "        self.done = np.zeros(max_size)\n",
    "        self.rng = np.random.default_rng(seed=seed)\n",
    "        \n",
    "        self.step = 0\n",
    "        self.len = 0\n",
    "\n",
    "        self.action = np.zeros((max_size, *action_space.shape), dtype=int)\n",
    "        self.reward = np.zeros(max_size)\n",
    "\n",
    "        self.current_state = np.zeros((max_size, *observation_space.shape))\n",
    "        self.next_state = np.zeros((max_size, *observation_space.shape))\n",
    "\n",
    "    def add(self, current_observation: np.ndarray, action: np.ndarray, reward: float, next_observation: np.ndarray, done: bool) -> None:\n",
    "        \"\"\"Add a new entry to the buffer.\n",
    "\n",
    "        Parameters:\n",
    "            current_observation: environment state observed at the current step\n",
    "            action: action taken by the model\n",
    "            reward: reward received after taking the action\n",
    "            next_observation: environment state obversed after taking the action\n",
    "            done: whether the episode has ended or not\"\"\"\n",
    "        \n",
    "        self.current_state[self.step] = current_observation\n",
    "        self.action[self.step] = action\n",
    "        self.reward[self.step] = reward\n",
    "        self.next_state[self.step] = next_observation\n",
    "        self.done[self.step] = done\n",
    "        self.step = (self.step + 1) % self.max_size\n",
    "        self.len = min(self.len + 1, self.max_size)\n",
    "        \n",
    "    def sample(self, n_samples: int, replace: bool = True) -> tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "        \"\"\"Randomly samples `n_samples` from the buffer.\n",
    "\n",
    "        Parameters:\n",
    "            n_samples: number of samples to select\n",
    "            replace: sample with or without replacement\n",
    "\n",
    "        Returns:\n",
    "            current observations, actions, rewards, next observations, done\"\"\"\n",
    "        indicies = self.rng.choice(self.len, size=n_samples, replace=replace)\n",
    "        \n",
    "        return (\n",
    "            self.current_state[indicies],\n",
    "            self.action[indicies],\n",
    "            self.reward[indicies],\n",
    "            self.next_state[indicies],\n",
    "            self.done[indicies]\n",
    "        )\n",
    "\n",
    "    def clear(self) -> None:\n",
    "        \"\"\"Clears the buffer\"\"\"\n",
    "        self.step = 0\n",
    "        self.len = 0\n",
    "\n",
    "    def __getitem__(self, index: int) -> tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "        \"\"\"Gets a sample at `index`\n",
    "\n",
    "        Parameters:\n",
    "            index: index of the sample to get\n",
    "\n",
    "        Returns:\n",
    "            current observation, action, reward, next observation, done\"\"\"\n",
    "        return (\n",
    "            self.current_state[index], \n",
    "            self.action[index], \n",
    "            self.reward[index], \n",
    "            self.next_state[index], \n",
    "            self.done[index]\n",
    "        )\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Returns the number of entries in the buffer\"\"\"\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669485c5-5787-4ffa-82f2-58f6f0acc151",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc62c869-195b-4323-bdb4-dd53879455c9",
   "metadata": {},
   "source": [
    "Implement your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a572a086-e9ce-4194-8809-54a8e05477d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(prefix: str | None = None, suffix: str | None = None, separator: str = '/') -> str | None:\n",
    "    return prefix and prefix + separator + suffix or suffix or None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "025c3007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(\n",
    "    input_features: int,\n",
    "    a_features: tuple,\n",
    "    features: int,\n",
    "    out_features: tuple,\n",
    "    blocks: int, \n",
    "    activation: str | tf.keras.layers.Activation | None = 'silu',\n",
    "    dropout: float = 0.4,\n",
    "    multiply_freq: int = 1,\n",
    "    kind_of_model: str | None = None,\n",
    "    name: str | None = None\n",
    ") -> tf.keras.Model:\n",
    "\n",
    "    if kind_of_model == 'policy':\n",
    "        inputs = x = tf.keras.layers.Input(input_features, name=get_name(name, 'obs_input'))\n",
    "    else:\n",
    "        obs_input = tf.keras.layers.Input(input_features, name=get_name(name, 'obs_input'))\n",
    "        a_input = tf.keras.layers.Input(a_features, name=get_name(name, 'a_input'))\n",
    "        \n",
    "        inputs = [obs_input, a_input]\n",
    "        x = tf.keras.layers.Concatenate()(inputs)\n",
    "\n",
    "    for i in range(blocks):\n",
    "        x = tf.keras.layers.Dense(features, activation=activation, name=get_name(name, f'Dense_f_{i}'))(x)\n",
    "        x = tf.keras.layers.Dense(features * 2, activation=activation, name=get_name(name, f'Dense_s_{i}'))(x)\n",
    "\n",
    "        if multiply_freq > 0 and (i + 1) % multiply_freq == 0:\n",
    "            features *= 2\n",
    "\n",
    "        if dropout > 0:\n",
    "            x = tf.keras.layers.Dropout(dropout, name=get_name(name, f'Dropout_{i}'))(x)\n",
    "\n",
    "    if kind_of_model == 'policy':\n",
    "        x = tf.keras.layers.Dense(out_features, activation='tanh', name=get_name(name, 'Prediction'))(x)\n",
    "    else:\n",
    "        x = tf.keras.layers.Dense(out_features, name=get_name(name, 'Prediction'))(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs=inputs, outputs=x, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2cc1a3-3e45-4aac-8936-d5d45cc256f1",
   "metadata": {},
   "source": [
    "# Play the game"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02aa11b5-0ca1-4bfb-91a0-33a4f8922ae9",
   "metadata": {},
   "source": [
    "Implement interacting with the environment and storing entries to the replay buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b333e6b3-853a-4cb7-aea3-8c501d0247d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_game(model: tf.keras.Model, buffer: ReplayBuffer | None, env: gym.Env, max_steps: int, observation: np.ndarray | None = None) -> np.ndarray:\n",
    "    \"\"\"Play game and record\n",
    "\n",
    "    Parameters:\n",
    "        model: the model to get actions with\n",
    "        buffer: replay buffer to store the entries to\n",
    "        env: environment to play\n",
    "        max_steps: maximal number of steps to perform\n",
    "        observation: the observation to resume from\n",
    "\n",
    "    Returns:\n",
    "        the last observation\"\"\"\n",
    "    if observation is None:\n",
    "        observation, _ = env.reset()\n",
    "\n",
    "    buffer = buffer if buffer is not None else ReplayBuffer(1)\n",
    "\n",
    "    for _ in range(max_steps):\n",
    "        a = model(observation[None], training=False).numpy()[0] # Observe state `s` and select action `a`\n",
    "        a = tf.clip_by_value(a + tf.random.normal((4,)).numpy(), -1.0, 1.0)\n",
    "        \n",
    "        new_observation, score, done, terminated, _ = env.step(a) # Execute `a` in the environment\n",
    "        \n",
    "        buffer.add(observation, a, score, new_observation, done) # Store `(s, a, r, s', d)` in buffer\n",
    "\n",
    "        if done or terminated: # If `s'` is terminal, reset environment state\n",
    "            observation, _ = env.reset()\n",
    "            continue\n",
    "            \n",
    "        observation = new_observation\n",
    "\n",
    "    return observation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971ad3a7-0487-49d3-9ca4-6b6bbc3fa450",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9775cbc-77a8-4b02-ab0a-3fbb22b3e958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ddpg_loss(\n",
    "    current_observation: tf.Tensor, \n",
    "    action: tf.Tensor, \n",
    "    reward: tf.Tensor, \n",
    "    next_observation: tf.Tensor,\n",
    "    done: tf.Tensor,\n",
    "    q_model: tf.keras.Model,\n",
    "    policy_model: tf.keras.Model,\n",
    "    target_q_model: tf.keras.Model,\n",
    "    target_policy_model: tf.keras.Model,\n",
    "    gamma: float\n",
    ") -> tuple[tf.Tensor, tf.Tensor]:\n",
    "    \"\"\"Computes Deep Deterministic Policy Gradient.\n",
    "\n",
    "    Parameters:\n",
    "        current_observation: observations at the current time step\n",
    "        action: actions taken at the current time step\n",
    "        reward: rewards at the current time step\n",
    "        next_observation: observations at the next time step\n",
    "        done: whether the episode has ended or not\n",
    "        q_model: q-function model\n",
    "        policy_model: action prediction model\n",
    "        target_q_model: target q-function model\n",
    "        target_policy_model: target action prediction model\n",
    "        gamma: discount\n",
    "\n",
    "    Returns:\n",
    "        Computed losses for q-function and policy models\"\"\"\n",
    "    \n",
    "    q_current = q_model((current_observation, action))\n",
    "    q_next = target_q_model((next_observation, target_policy_model(next_observation)))\n",
    "\n",
    "    q_ref = reward + gamma * (1. - done) * q_next\n",
    "    q_loss = tf.math.reduce_mean(tf.square(q_current - q_ref))\n",
    "\n",
    "    policy_loss = -tf.math.reduce_mean(q_model((current_observation, policy_model(current_observation))))\n",
    "\n",
    "    return q_loss, policy_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78458a1f-054a-463a-934f-ac3f669c0e27",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb0aaa7-6ae5-45dc-9c52-04c474ec3ecc",
   "metadata": {},
   "source": [
    "Create models, replay buffers, optimizer. Implement training loop, show training progress and perform model evaluation once in a while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "139138b8-f63c-4a2f-8793-4f96d25a353a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Timofeev_Andrey\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Timofeev_Andrey/obs_input (Inp  [(None, 24)]        0           []                               \n",
      " utLayer)                                                                                         \n",
      "                                                                                                  \n",
      " Timofeev_Andrey/a_input (Input  [(None, 4)]         0           []                               \n",
      " Layer)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 28)           0           ['Timofeev_Andrey/obs_input[0][0]\n",
      "                                                                 ',                               \n",
      "                                                                  'Timofeev_Andrey/a_input[0][0]']\n",
      "                                                                                                  \n",
      " Timofeev_Andrey/Dense_f_0 (Den  (None, 256)         7424        ['concatenate[0][0]']            \n",
      " se)                                                                                              \n",
      "                                                                                                  \n",
      " Timofeev_Andrey/Dense_s_0 (Den  (None, 512)         131584      ['Timofeev_Andrey/Dense_f_0[0][0]\n",
      " se)                                                             ']                               \n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " Timofeev_Andrey/obs_input (Inp  [(None, 24)]        0           []                               \n",
      " utLayer)                                                                                         \n",
      "                                                                                                  \n",
      " Timofeev_Andrey/a_input (Input  [(None, 4)]         0           []                               \n",
      " Layer)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 28)           0           ['Timofeev_Andrey/obs_input[0][0]\n",
      "                                                                 ',                               \n",
      "                                                                  'Timofeev_Andrey/a_input[0][0]']\n",
      "                                                                                                  \n",
      " Timofeev_Andrey/Dense_f_0 (Den  (None, 256)         7424        ['concatenate[0][0]']            \n",
      " se)                                                                                              \n",
      "                                                                                                  \n",
      " Timofeev_Andrey/Dense_s_0 (Den  (None, 512)         131584      ['Timofeev_Andrey/Dense_f_0[0][0]\n",
      " se)                                                             ']                               \n",
      "                                                                                                  \n",
      " Timofeev_Andrey/Dropout_0 (Dro  (None, 512)         0           ['Timofeev_Andrey/Dense_s_0[0][0]\n",
      " pout)                                                           ']                               \n",
      "                                                                                                  \n",
      " Timofeev_Andrey/Dense_f_1 (Den  (None, 256)         131328      ['Timofeev_Andrey/Dropout_0[0][0]\n",
      " se)                                                             ']                               \n",
      "                                                                                                  \n",
      " Timofeev_Andrey/Dense_s_1 (Den  (None, 512)         131584      ['Timofeev_Andrey/Dense_f_1[0][0]\n",
      " se)                                                             ']                               \n",
      "                                                                                                  \n",
      " Timofeev_Andrey/Dropout_1 (Dro  (None, 512)         0           ['Timofeev_Andrey/Dense_s_1[0][0]\n",
      " pout)                                                           ']                               \n",
      "                                                                                                  \n",
      " Timofeev_Andrey/Dense_f_2 (Den  (None, 512)         262656      ['Timofeev_Andrey/Dropout_1[0][0]\n",
      " se)                                                             ']                               \n",
      "                                                                                                  \n",
      " Timofeev_Andrey/Dense_s_2 (Den  (None, 1024)        525312      ['Timofeev_Andrey/Dense_f_2[0][0]\n",
      " se)                                                             ']                               \n",
      "                                                                                                  \n",
      " Timofeev_Andrey/Dropout_2 (Dro  (None, 1024)        0           ['Timofeev_Andrey/Dense_s_2[0][0]\n",
      " pout)                                                           ']                               \n",
      "                                                                                                  \n",
      " Timofeev_Andrey/Dense_f_3 (Den  (None, 512)         524800      ['Timofeev_Andrey/Dropout_2[0][0]\n",
      " se)                                                             ']                               \n",
      "                                                                                                  \n",
      " Timofeev_Andrey/Dense_s_3 (Den  (None, 1024)        525312      ['Timofeev_Andrey/Dense_f_3[0][0]\n",
      " se)                                                             ']                               \n",
      "                                                                                                  \n",
      " Timofeev_Andrey/Dropout_3 (Dro  (None, 1024)        0           ['Timofeev_Andrey/Dense_s_3[0][0]\n",
      " pout)                                                           ']                               \n",
      "                                                                                                  \n",
      " Timofeev_Andrey/Dense_f_4 (Den  (None, 1024)        1049600     ['Timofeev_Andrey/Dropout_3[0][0]\n",
      " se)                                                             ']                               \n",
      "                                                                                                  \n",
      " Timofeev_Andrey/Dense_s_4 (Den  (None, 2048)        2099200     ['Timofeev_Andrey/Dense_f_4[0][0]\n",
      " se)                                                             ']                               \n",
      "                                                                                                  \n",
      " Timofeev_Andrey/Dropout_4 (Dro  (None, 2048)        0           ['Timofeev_Andrey/Dense_s_4[0][0]\n",
      " pout)                                                           ']                               \n",
      "                                                                                                  \n",
      " Timofeev_Andrey/Prediction (De  (None, 1)           2049        ['Timofeev_Andrey/Dropout_4[0][0]\n",
      " nse)                                                            ']                               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5,390,849\n",
      "Trainable params: 5,390,849\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model(enviroment.observation_space.shape[0], enviroment.action_space.shape, 256, 1, 5, name='Timofeev_Andrey', dropout=0.2, multiply_freq=2, activation='relu')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5d9d794",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_model = get_model(enviroment.observation_space.shape[0], enviroment.action_space.shape, 256, 1, 5, name='Target_Timofeev_Andrey', multiply_freq=2, activation='relu')\n",
    "target_model.trainable = False\n",
    "target_model.set_weights(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f82a7f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Policy_Timofeev_Andrey\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Policy_Timofeev_Andrey/obs_  [(None, 24)]             0         \n",
      " input (InputLayer)                                              \n",
      "                                                                 \n",
      " Policy_Timofeev_Andrey/Dens  (None, 256)              6400      \n",
      " e_f_0 (Dense)                                                   \n",
      "                                                                 \n",
      " Policy_Timofeev_Andrey/Dens  (None, 512)              131584    \n",
      " e_s_0 (Dense)                                                   \n",
      "                                                                 \n",
      " Policy_Timofeev_Andrey/Drop  (None, 512)              0         \n",
      " out_0 (Dropout)                                                 \n",
      "                                                                 \n",
      " Policy_Timofeev_Andrey/Dens  (None, 256)              131328    \n",
      " e_f_1 (Dense)                                                   \n",
      "                                                                 \n",
      " Policy_Timofeev_Andrey/Dens  (None, 512)              131584    \n",
      " e_s_1 (Dense)                                                   \n",
      "                                                                 \n",
      " Policy_Timofeev_Andrey/Drop  (None, 512)              0         \n",
      " out_1 (Dropout)                                                 \n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Policy_Timofeev_Andrey/obs_  [(None, 24)]             0         \n",
      " input (InputLayer)                                              \n",
      "                                                                 \n",
      " Policy_Timofeev_Andrey/Dens  (None, 256)              6400      \n",
      " e_f_0 (Dense)                                                   \n",
      "                                                                 \n",
      " Policy_Timofeev_Andrey/Dens  (None, 512)              131584    \n",
      " e_s_0 (Dense)                                                   \n",
      "                                                                 \n",
      " Policy_Timofeev_Andrey/Drop  (None, 512)              0         \n",
      " out_0 (Dropout)                                                 \n",
      "                                                                 \n",
      " Policy_Timofeev_Andrey/Dens  (None, 256)              131328    \n",
      " e_f_1 (Dense)                                                   \n",
      "                                                                 \n",
      " Policy_Timofeev_Andrey/Dens  (None, 512)              131584    \n",
      " e_s_1 (Dense)                                                   \n",
      "                                                                 \n",
      " Policy_Timofeev_Andrey/Drop  (None, 512)              0         \n",
      " out_1 (Dropout)                                                 \n",
      "                                                                 \n",
      " Policy_Timofeev_Andrey/Dens  (None, 512)              262656    \n",
      " e_f_2 (Dense)                                                   \n",
      "                                                                 \n",
      " Policy_Timofeev_Andrey/Dens  (None, 1024)             525312    \n",
      " e_s_2 (Dense)                                                   \n",
      "                                                                 \n",
      " Policy_Timofeev_Andrey/Drop  (None, 1024)             0         \n",
      " out_2 (Dropout)                                                 \n",
      "                                                                 \n",
      " Policy_Timofeev_Andrey/Dens  (None, 512)              524800    \n",
      " e_f_3 (Dense)                                                   \n",
      "                                                                 \n",
      " Policy_Timofeev_Andrey/Dens  (None, 1024)             525312    \n",
      " e_s_3 (Dense)                                                   \n",
      "                                                                 \n",
      " Policy_Timofeev_Andrey/Drop  (None, 1024)             0         \n",
      " out_3 (Dropout)                                                 \n",
      "                                                                 \n",
      " Policy_Timofeev_Andrey/Pred  (None, 4)                4100      \n",
      " iction (Dense)                                                  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,243,076\n",
      "Trainable params: 2,243,076\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "policy_model = get_model(enviroment.observation_space.shape[0], enviroment.action_space.shape, 256, 4, 4, name='Policy_Timofeev_Andrey', multiply_freq=2, kind_of_model='policy')\n",
    "policy_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "787e12e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_policy_model = get_model(enviroment.observation_space.shape[0], enviroment.action_space.shape, 256, 4, 4, name='Target_Policy_Timofeev_Andrey', multiply_freq=2, kind_of_model='policy')\n",
    "target_policy_model.trainable = False\n",
    "target_policy_model.set_weights(policy_model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1dc75d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_buffer = ReplayBuffer(15000, observation_space=enviroment.observation_space, action_space=enviroment.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2eff362",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_buffer = ReplayBuffer(100, observation_space=eval_enviroment.observation_space, action_space=eval_enviroment.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c250ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(1e-4, clipnorm=5, decay=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1c708e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10000\n",
    "batch_size = 512\n",
    "update_frequency = 512\n",
    "eval_frequency = 512\n",
    "steps_per_epoch = 32\n",
    "eval_steps = 1000\n",
    "initial_samples = 10000\n",
    "n_evals = 5\n",
    "eval_threshold = 400\n",
    "polyak = 0.94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f871b46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mulpiply_weights(model: tf.keras.Model, target_model: tf.keras.Model, polyak: float | int) -> list[np.ndarray]:\n",
    "    return [polyak * target_weights + (1. - polyak) * model_weights for target_weights, model_weights in zip(target_model.get_weights(), model.get_weights())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02a71574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.46085668,  0.00721871, -0.02799077,  0.01535085, -0.8375221 ,\n",
       "        0.00468056, -0.6199409 , -0.02397528,  0.        ,  0.85052675,\n",
       "       -0.9983081 ,  1.0496491 ,  2.4198844 ,  0.        ,  0.2563027 ,\n",
       "        0.25921342,  0.26828527,  0.28463942,  0.31054363,  0.35028923,\n",
       "        0.4123208 ,  0.5151078 ,  0.70731956,  1.        ], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "play_game(policy_model, train_buffer, enviroment, initial_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fefb8c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84595f72751e44d7b0c52d1cc6edd376",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "q_losses = []\n",
    "p_losses = []\n",
    "total_q_loss = 0\n",
    "total_p_loss = 0\n",
    "eval_score = 0\n",
    "best_score = 0\n",
    "\n",
    "s, _ = enviroment.reset()\n",
    "pbar = tqdm.trange(epochs)\n",
    "for i in pbar:\n",
    "    \n",
    "    s = play_game(policy_model, train_buffer, enviroment, steps_per_epoch, observation=s) # Select action, play and store in buffer\n",
    "    \n",
    "    vals = train_buffer.sample(batch_size) # Randomly sample a batch of transitions\n",
    "\n",
    "    with tf.GradientTape(watch_accessed_variables=False) as q_g, tf.GradientTape(watch_accessed_variables=False) as p_g:\n",
    "        q_g.watch(model.trainable_weights)\n",
    "        p_g.watch(policy_model.trainable_weights)\n",
    "        q_loss, policy_loss = ddpg_loss(*vals, model, policy_model, target_model, target_policy_model, 0.99) # MSBE and mean score from Policy\n",
    "\n",
    "    q_gradient = q_g.gradient(q_loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(q_gradient, model.trainable_weights))\n",
    "\n",
    "    p_gradient = p_g.gradient(policy_loss, policy_model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(p_gradient, policy_model.trainable_weights))\n",
    "    \n",
    "    q_losses.append(q_loss.numpy())\n",
    "    p_losses.append(policy_loss.numpy())\n",
    "    \n",
    "    total_q_loss += q_losses[-1]\n",
    "    total_p_loss += p_losses[-1]\n",
    "\n",
    "    if (i + 1) % update_frequency == 0:\n",
    "        target_model.set_weights(mulpiply_weights(model, target_model, polyak))\n",
    "        target_policy_model.set_weights(mulpiply_weights(policy_model, target_policy_model, polyak))\n",
    "\n",
    "    if (i + 1) % eval_frequency == 0:\n",
    "        if best_score > eval_score:\n",
    "            best_score = eval_score\n",
    "\n",
    "            model_directory = f'./my_models_walker/dir_model_walker_{best_score}/'\n",
    "            \n",
    "            if not os.path.exists(model_directory):\n",
    "                os.makedirs(model_directory)\n",
    "            \n",
    "            model.save_weights(model_directory + f'model_{best_score}')\n",
    "\n",
    "        eval_score = 0\n",
    "\n",
    "        for i in range(n_evals):\n",
    "            eval_buffer.clear()\n",
    "            play_game(policy_model, eval_buffer, eval_enviroment, eval_steps)\n",
    "            eval_score += eval_buffer.reward[:len(eval_buffer)].sum()\n",
    "\n",
    "        eval_score /= n_evals\n",
    "        if eval_score >= eval_threshold:\n",
    "            break\n",
    "\n",
    "    pbar.set_description(f'Qloss: {q_losses[-1]:.5f}; AllQloss: {total_q_loss / (i + 1):.5f}; Ploss: {p_losses[-1]:.5f}; AllPloss: {total_p_loss / (i + 1):.5f}; E: {eval_score:.5f}; BE: {best_score:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e312861",
   "metadata": {},
   "outputs": [],
   "source": [
    "enviroment.close()\n",
    "eval_enviroment.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd5b44e-55cd-43bb-89dd-87c28cc10a9c",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965e5731-8d24-4482-82ed-7226fb18fa5c",
   "metadata": {},
   "source": [
    "Test the model on the environment and get a cool video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4931a937",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_gameplay(model: tf.keras.Model, render_mode: str = 'human', n_frames: int = 500, buffer_capacity: int = 500):\n",
    "    env = gym.make(env_name, hardcore=False, render_mode=render_mode)\n",
    "    buffer = ReplayBuffer(buffer_capacity, env.observation_space, env.action_space)\n",
    "    play_game(model, buffer, env, n_frames)\n",
    "    \n",
    "    if render_mode != 'human':\n",
    "        save_video(env.render(), './videos_walker_2', video_length=n_frames, fps=24) #if you wanna use this line change 'render_mode' -> 'rgb_array_list'\n",
    "    \n",
    "    return buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ec9bccad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x2b0c03f0880>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('./my_models_walker/dir_model_walker_-90.67401897754556/model_-90.67401897754556')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "57e4ea04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video d:\\Andrey\\Master\\2_year\\base_ml\\RL\\videos_walker_2/rl-video-episode-0.mp4.\n",
      "Moviepy - Writing video d:\\Andrey\\Master\\2_year\\base_ml\\RL\\videos_walker_2/rl-video-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready d:\\Andrey\\Master\\2_year\\base_ml\\RL\\videos_walker_2/rl-video-episode-0.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "buffer = save_gameplay(policy_model, render_mode='rgb_array_list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "49e78353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-736.1084953928827"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer.reward.sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
